{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e6181f8",
   "metadata": {},
   "source": [
    "# LangChain and Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1db1517d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langgraph-prebuilt 1.0.4 requires langchain-core>=1.0.0, but you have langchain-core 0.3.79 which is incompatible.\n",
      "langchain-text-splitters 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.3.79 which is incompatible.\n",
      "langchain-openai 1.0.3 requires langchain-core<2.0.0,>=1.0.2, but you have langchain-core 0.3.79 which is incompatible.\n",
      "langchain-classic 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.3.79 which is incompatible.\n",
      "langchain-community 0.4.1 requires langchain-core<2.0.0,>=1.0.1, but you have langchain-core 0.3.79 which is incompatible.\n",
      "langchain 1.0.7 requires langchain-core<2.0.0,>=1.0.4, but you have langchain-core 0.3.79 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q langchain-google-genai google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8100d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain-core\n",
      "Version: 0.3.79\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /home/jonee/Work/py-langchain/venv/lib/python3.13/site-packages\n",
      "Requires: jsonpatch, langsmith, packaging, pydantic, PyYAML, tenacity, typing-extensions\n",
      "Required-by: langchain, langchain-classic, langchain-community, langchain-google-genai, langchain-openai, langchain-text-splitters, langgraph, langgraph-checkpoint, langgraph-prebuilt\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8cbec0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE_API_KEY loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    print(\"Error: GOOGLE_API_KEY not found in environment variables.\")\n",
    "else:\n",
    "    print(\"GOOGLE_API_KEY loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75eba754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.5-flash-preview-05-20\n",
      "models/gemini-2.5-flash\n",
      "models/gemini-2.5-flash-lite-preview-06-17\n",
      "models/gemini-2.5-pro-preview-05-06\n",
      "models/gemini-2.5-pro-preview-06-05\n",
      "models/gemini-2.5-pro\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "models/learnlm-2.0-flash-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/gemma-3n-e4b-it\n",
      "models/gemma-3n-e2b-it\n",
      "models/gemini-flash-latest\n",
      "models/gemini-flash-lite-latest\n",
      "models/gemini-pro-latest\n",
      "models/gemini-2.5-flash-lite\n",
      "models/gemini-2.5-flash-image-preview\n",
      "models/gemini-2.5-flash-image\n",
      "models/gemini-2.5-flash-preview-09-2025\n",
      "models/gemini-2.5-flash-lite-preview-09-2025\n",
      "models/gemini-robotics-er-1.5-preview\n",
      "models/gemini-2.5-computer-use-preview-10-2025\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/gemini-embedding-001\n",
      "models/aqa\n",
      "models/imagen-4.0-generate-preview-06-06\n",
      "models/imagen-4.0-ultra-generate-preview-06-06\n",
      "models/imagen-4.0-generate-001\n",
      "models/imagen-4.0-ultra-generate-001\n",
      "models/imagen-4.0-fast-generate-001\n",
      "models/veo-2.0-generate-001\n",
      "models/veo-3.0-generate-001\n",
      "models/veo-3.0-fast-generate-001\n",
      "models/veo-3.1-generate-preview\n",
      "models/veo-3.1-fast-generate-preview\n",
      "models/gemini-2.0-flash-live-001\n",
      "models/gemini-live-2.5-flash-preview\n",
      "models/gemini-2.5-flash-live-preview\n",
      "models/gemini-2.5-flash-native-audio-latest\n",
      "models/gemini-2.5-flash-native-audio-preview-09-2025\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "for model in genai.list_models():\n",
    "    print(model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e1e913",
   "metadata": {},
   "source": [
    "## Integrating Gemini with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ae67d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'langchain' has no attribute 'verbose'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_google_genai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGoogleGenerativeAI\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m llm = \u001b[43mChatGoogleGenerativeAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini-2.5-flash\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m response = llm.invoke(\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mWrite a paragraph about object oriented programing\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m )\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/py-langchain/venv/lib/python3.13/site-packages/langchain_core/load/serializable.py:115\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    114\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419  # Intentional blank docstring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/py-langchain/venv/lib/python3.13/site-packages/langchain_core/language_models/base.py:108\u001b[39m, in \u001b[36m_get_verbosity\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_verbosity\u001b[39m() -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_verbose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/py-langchain/venv/lib/python3.13/site-packages/langchain_core/globals.py:86\u001b[39m, in \u001b[36mget_verbose\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     67\u001b[39m         warnings.filterwarnings(\n\u001b[32m     68\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     69\u001b[39m             message=(\n\u001b[32m   (...)\u001b[39m\u001b[32m     72\u001b[39m             ),\n\u001b[32m     73\u001b[39m         )\n\u001b[32m     74\u001b[39m         \u001b[38;5;66;03m# N.B.: This is a workaround for an unfortunate quirk of Python's\u001b[39;00m\n\u001b[32m     75\u001b[39m         \u001b[38;5;66;03m#       module-level `__getattr__()` implementation:\u001b[39;00m\n\u001b[32m     76\u001b[39m         \u001b[38;5;66;03m# https://github.com/langchain-ai/langchain/pull/11311#issuecomment-1743780004\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     84\u001b[39m         \u001b[38;5;66;03m# deprecation warnings directing them to use `set_verbose()` when they\u001b[39;00m\n\u001b[32m     85\u001b[39m         \u001b[38;5;66;03m# import `langchain.verbose`.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m         old_verbose = \u001b[43mlangchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     88\u001b[39m     old_verbose = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: module 'langchain' has no attribute 'verbose'"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.9)\n",
    "response = llm.invoke(\n",
    "    \"Write a paragraph about object oriented programing\",\n",
    ")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e870ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'langchain' has no attribute 'verbose'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_classic\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchains\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLMChain\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mprompt_toolkit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m prompt\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m llm = \u001b[43mChatGoogleGenerativeAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini-pro\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m prompt = PromptTemplate.from_template(\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mYou are a content creator. Write me a tweet about \u001b[39m\u001b[38;5;132;01m{topic}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m )\n\u001b[32m     10\u001b[39m chain = LLMChain(llm=llm, prompt=prompt, verbose=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/py-langchain/venv/lib/python3.13/site-packages/langchain_core/load/serializable.py:115\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    114\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419  # Intentional blank docstring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/py-langchain/venv/lib/python3.13/site-packages/langchain_core/language_models/base.py:108\u001b[39m, in \u001b[36m_get_verbosity\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_verbosity\u001b[39m() -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_verbose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/py-langchain/venv/lib/python3.13/site-packages/langchain_core/globals.py:86\u001b[39m, in \u001b[36mget_verbose\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     67\u001b[39m         warnings.filterwarnings(\n\u001b[32m     68\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     69\u001b[39m             message=(\n\u001b[32m   (...)\u001b[39m\u001b[32m     72\u001b[39m             ),\n\u001b[32m     73\u001b[39m         )\n\u001b[32m     74\u001b[39m         \u001b[38;5;66;03m# N.B.: This is a workaround for an unfortunate quirk of Python's\u001b[39;00m\n\u001b[32m     75\u001b[39m         \u001b[38;5;66;03m#       module-level `__getattr__()` implementation:\u001b[39;00m\n\u001b[32m     76\u001b[39m         \u001b[38;5;66;03m# https://github.com/langchain-ai/langchain/pull/11311#issuecomment-1743780004\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     84\u001b[39m         \u001b[38;5;66;03m# deprecation warnings directing them to use `set_verbose()` when they\u001b[39;00m\n\u001b[32m     85\u001b[39m         \u001b[38;5;66;03m# import `langchain.verbose`.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m         old_verbose = \u001b[43mlangchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     88\u001b[39m     old_verbose = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: module 'langchain' has no attribute 'verbose'"
     ]
    }
   ],
   "source": [
    "from langchain_classic.prompts import PromptTemplate\n",
    "from langchain_classic.chains import LLMChain\n",
    "from prompt_toolkit import prompt\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"You are a content creator. Write me a tweet about {topic}\"\n",
    ")\n",
    "chain = LLMChain(llm=llm, prompt=prompt, verbose=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
